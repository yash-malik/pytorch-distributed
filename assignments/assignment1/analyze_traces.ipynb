{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Trace Analysis with HTA\n",
    "\n",
    "Use Holistic Trace Analysis to compare training setups:\n",
    "- Baseline (Single GPU)\n",
    "- DDP (DistributedDataParallel)\n",
    "- FSDP with different sharding strategies\n",
    "\n",
    "Key analyses:\n",
    "1. Temporal breakdown (compute vs communication vs idle)\n",
    "2. Trace diff (exact operation differences)\n",
    "3. Memory usage patterns\n",
    "4. Communication overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install HTA if needed\n",
    "# !pip install HolisticTraceAnalysis\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from hta.trace_analysis import TraceAnalysis\n",
    "from hta.trace_diff import TraceDiff, LabeledTrace, DeviceType\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Traces\n",
    "\n",
    "Load all the traces generated from training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define trace directories\n",
    "trace_dirs = {\n",
    "    'baseline': 'outputs/traces/baseline/',\n",
    "    'ddp': 'outputs/traces/ddp/',\n",
    "    'fsdp_full': 'outputs/traces/fsdp_full_shard/',\n",
    "    'fsdp_grad': 'outputs/traces/fsdp_shard_grad_op/'\n",
    "}\n",
    "\n",
    "# Load traces for temporal analysis\n",
    "traces = {}\n",
    "for name, trace_dir in trace_dirs.items():\n",
    "    print(f\"Loading {name}...\")\n",
    "    traces[name] = TraceAnalysis(trace_dir=trace_dir)\n",
    "\n",
    "print(\"\\n‚úÖ All traces loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Breakdown Analysis\n",
    "\n",
    "See how GPU time is spent in each setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get temporal breakdown for all setups\n",
    "breakdowns = {}\n",
    "for name, trace in traces.items():\n",
    "    print(f\"\\nüìä {name.upper()} Temporal Breakdown:\")\n",
    "    breakdown = trace.get_temporal_breakdown(visualize=False)\n",
    "    breakdowns[name] = breakdown\n",
    "    print(breakdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, breakdown) in enumerate(breakdowns.items()):\n",
    "    # Handle different column naming conventions\n",
    "    data = breakdown[['compute_time(us)', 'non_compute_time(us)', 'idle_time(us)']].iloc[0]\n",
    "    \n",
    "    axes[idx].pie(data, labels=['Compute', 'Non-Compute', 'Idle'], autopct='%1.1f%%')\n",
    "    axes[idx].set_title(f'{name.upper()} Time Breakdown')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Communication-Computation Overlap Analysis\n",
    "\n",
    "Analyze how well communication overlaps with computation in distributed setups.\n",
    "Good overlap means the GPU is computing while communication happens in the background,\n",
    "improving overall efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute communication-computation overlap for distributed setups\n",
    "# Skip baseline as it has no communication\n",
    "for name in ['ddp', 'fsdp_full', 'fsdp_grad']:\n",
    "    if name in traces:\n",
    "        print(f\"\\nüìä {name.upper()} Communication-Computation Overlap:\")\n",
    "        overlap_df = traces[name].get_comm_comp_overlap(visualize=False)\n",
    "        if overlap_df is not None and len(overlap_df) > 0:\n",
    "            print(overlap_df)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No overlap data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Overlap Metrics\n",
    "\n",
    "Key concepts:\n",
    "- **comm_exposed**: Communication time that is NOT overlapped with computation (bad)\n",
    "- **total_comm_duration**: Total time spent in communication operations\n",
    "- **Overlap %**: Percentage of communication that is hidden by computation (good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare LabeledTrace Objects for TraceDiff\n",
    "\n",
    "TraceDiff requires LabeledTrace objects and specific rank/iteration numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LabeledTrace objects for each setup\n",
    "labeled_traces = {\n",
    "    'baseline': LabeledTrace(label=\"Baseline\", trace_dir='outputs/traces/baseline/'),\n",
    "    'ddp': LabeledTrace(label=\"DDP\", trace_dir='outputs/traces/ddp/'),\n",
    "    'fsdp_full': LabeledTrace(label=\"FSDP_Full\", trace_dir='outputs/traces/fsdp_full_shard/'),\n",
    "    'fsdp_grad': LabeledTrace(label=\"FSDP_Grad\", trace_dir='outputs/traces/fsdp_shard_grad_op/')\n",
    "}\n",
    "\n",
    "# Check available ranks and iterations for each trace\n",
    "for name, lt in labeled_traces.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Ranks: {lt.ranks()}\")\n",
    "    print(f\"  Iterations: {lt.iterations()[:5]}...\")  # Show first 5 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Two Setups (Trace Diff)\n",
    "\n",
    "Use TraceDiff to compare operator counts and durations between setups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_setups(trace1, trace2, name1, name2, rank1=0, rank2=0, iteration=0, device_type=DeviceType.GPU):\n",
    "    \"\"\"\n",
    "    Compare two training setups using HTA TraceDiff.\n",
    "    \n",
    "    Args:\n",
    "        trace1, trace2: LabeledTrace objects\n",
    "        name1, name2: Names for display\n",
    "        rank1, rank2: Rank numbers for each trace\n",
    "        iteration: Iteration number to compare\n",
    "        device_type: DeviceType.CPU, DeviceType.GPU, or DeviceType.ALL\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Comparing: {name1} vs {name2}\")\n",
    "    print(f\"Rank: {rank1} vs {rank2}, Iteration: {iteration}, Device: {device_type.name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # Compare traces using class method\n",
    "        df_comp = TraceDiff.compare_traces(\n",
    "            trace1, trace2, \n",
    "            rank1, rank2, \n",
    "            iteration, iteration, \n",
    "            device_type\n",
    "        )\n",
    "        \n",
    "        if df_comp is None or len(df_comp) == 0:\n",
    "            print(\"\\n‚ö†Ô∏è  No differences found\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\nFound {len(df_comp)} operators\")\n",
    "        print(f\"\\nTop 10 operators by duration difference:\")\n",
    "        print(df_comp.nlargest(10, 'diff_duration')[['diff_duration', 'diff_counts']])\n",
    "        \n",
    "        # Show operators unique to trace2 (added operations)\n",
    "        col_name = f\"{trace1.label}_counts\"\n",
    "        if col_name in df_comp.columns:\n",
    "            added_ops = df_comp[df_comp[col_name] == 0]\n",
    "            if len(added_ops) > 0:\n",
    "                print(f\"\\nüÜï Operations added in {name2}: {len(added_ops)}\")\n",
    "                print(added_ops.head(10))\n",
    "        \n",
    "        # Get ops that were removed/added\n",
    "        ops_diff = TraceDiff.ops_diff(\n",
    "            trace1, trace2,\n",
    "            rank1, rank2,\n",
    "            iteration, iteration,\n",
    "            device_type\n",
    "        )\n",
    "        \n",
    "        if ops_diff and 'added' in ops_diff:\n",
    "            print(f\"\\nüì° Communication/collective operations added:\")\n",
    "            comm_ops = [op for op in ops_diff['added'] if any(x in op.lower() for x in ['nccl', 'allreduce', 'allgather', 'reduce_scatter', 'broadcast'])]\n",
    "            if comm_ops:\n",
    "                for op in comm_ops[:10]:\n",
    "                    print(f\"  - {op}\")\n",
    "        \n",
    "        return df_comp\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error comparing traces: {e}\")\n",
    "        print(\"This might be due to missing ranks/iterations in the traces.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Baseline vs DDP Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline with DDP\n",
    "# Note: baseline uses rank 0, DDP uses rank 0 as well\n",
    "# Iteration 4 is the first profiled iteration (profiler schedule: wait=2, warmup=2, active=6)\n",
    "diff_baseline_ddp = compare_two_setups(\n",
    "    labeled_traces['baseline'],\n",
    "    labeled_traces['ddp'],\n",
    "    'Baseline',\n",
    "    'DDP',\n",
    "    rank1=0,\n",
    "    rank2=0,\n",
    "    iteration=4,\n",
    "    device_type=DeviceType.GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. DDP vs FSDP Comparisons\n",
    "\n",
    "Compare DDP with different FSDP sharding strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDP vs FSDP FULL_SHARD\n",
    "diff_ddp_fsdp_full = compare_two_setups(\n",
    "    labeled_traces['ddp'],\n",
    "    labeled_traces['fsdp_full'],\n",
    "    'DDP',\n",
    "    'FSDP_FULL_SHARD',\n",
    "    rank1=0,\n",
    "    rank2=0,\n",
    "    iteration=4,\n",
    "    device_type=DeviceType.GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDP vs FSDP SHARD_GRAD_OP\n",
    "diff_ddp_fsdp_grad = compare_two_setups(\n",
    "    labeled_traces['ddp'],\n",
    "    labeled_traces['fsdp_grad'],\n",
    "    'DDP',\n",
    "    'FSDP_SHARD_GRAD_OP',\n",
    "    rank1=0,\n",
    "    rank2=0,\n",
    "    iteration=4,\n",
    "    device_type=DeviceType.GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSDP strategies comparison\n",
    "diff_fsdp_strategies = compare_two_setups(\n",
    "    labeled_traces['fsdp_full'],\n",
    "    labeled_traces['fsdp_grad'],\n",
    "    'FSDP_FULL_SHARD',\n",
    "    'FSDP_SHARD_GRAD_OP',\n",
    "    rank1=0,\n",
    "    rank2=0,\n",
    "    iteration=4,\n",
    "    device_type=DeviceType.GPU\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
